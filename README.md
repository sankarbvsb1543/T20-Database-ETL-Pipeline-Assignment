##T20 Cricket Database ETL Pipeline
Designed and implemented a scalable ETL pipeline using PySpark and SQL Server to process and manage T20 cricket match data, ensuring efficient data ingestion, transformation, and storage.

Implemented incremental load and full load strategies to handle large datasets, optimizing performance and reducing processing time.

Maintained Slowly Changing Dimensions (SCD) Type 1 and Type 2 to track historical changes in player and team data, ensuring data accuracy and enabling historical analysis.

Optimized cluster performance by fine-tuning Spark configurations, partitioning data, and leveraging parallel processing for efficient data handling.

Developed robust data pipelines to extract raw data from multiple sources, transform it using PySpark, and load it into SQL Server for querying and analysis.

Ensured data integrity and consistency by implementing error handling and logging mechanisms throughout the ETL process.

Technologies Used: PySpark, SQL Server, ETL Pipelines, Incremental Load, Full Load, Slowly Changing Dimensions (SCD Type 1 and Type 2), Cluster Performance Optimization, Data Partitioning, Parallel Processing.
